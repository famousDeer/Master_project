{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version 2.0.0+cu117\n",
      "torchvision version 0.15.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from models import VGG16\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "print(f\"torch version {torch.__version__}\")\n",
    "print(f\"torchvision version {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"/home/famousdeer/Desktop/Praca magisterska/Program/data\")\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "                                        transforms.RandomCrop(size=32,\n",
    "                                                              padding=4),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor()\n",
    "                                        ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                                        transforms.ToTensor()\n",
    "                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=ROOT,\n",
    "                                             train=True,\n",
    "                                             download=True,\n",
    "                                             transform=transform_train\n",
    "                                             )\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=ROOT,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = test_dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 16, 16]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          1,792\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 64, 32, 32]          36,928\n",
      "|    └─ReLU: 2-5                         [-1, 64, 32, 32]          --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 64, 16, 16]          --\n",
      "├─Sequential: 1-2                        [-1, 128, 8, 8]           --\n",
      "|    └─Conv2d: 2-7                       [-1, 128, 16, 16]         73,856\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 128, 16, 16]         256\n",
      "|    └─ReLU: 2-9                         [-1, 128, 16, 16]         --\n",
      "|    └─Conv2d: 2-10                      [-1, 128, 16, 16]         147,584\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 128, 16, 16]         256\n",
      "|    └─ReLU: 2-12                        [-1, 128, 16, 16]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 128, 8, 8]           --\n",
      "├─Sequential: 1-3                        [-1, 256, 4, 4]           --\n",
      "|    └─Conv2d: 2-14                      [-1, 256, 8, 8]           295,168\n",
      "|    └─BatchNorm2d: 2-15                 [-1, 256, 8, 8]           512\n",
      "|    └─ReLU: 2-16                        [-1, 256, 8, 8]           --\n",
      "|    └─Conv2d: 2-17                      [-1, 256, 8, 8]           590,080\n",
      "|    └─BatchNorm2d: 2-18                 [-1, 256, 8, 8]           512\n",
      "|    └─ReLU: 2-19                        [-1, 256, 8, 8]           --\n",
      "|    └─Conv2d: 2-20                      [-1, 256, 8, 8]           590,080\n",
      "|    └─BatchNorm2d: 2-21                 [-1, 256, 8, 8]           512\n",
      "|    └─ReLU: 2-22                        [-1, 256, 8, 8]           --\n",
      "|    └─MaxPool2d: 2-23                   [-1, 256, 4, 4]           --\n",
      "├─Sequential: 1-4                        [-1, 512, 2, 2]           --\n",
      "|    └─Conv2d: 2-24                      [-1, 512, 4, 4]           1,180,160\n",
      "|    └─BatchNorm2d: 2-25                 [-1, 512, 4, 4]           1,024\n",
      "|    └─ReLU: 2-26                        [-1, 512, 4, 4]           --\n",
      "|    └─Conv2d: 2-27                      [-1, 512, 4, 4]           2,359,808\n",
      "|    └─BatchNorm2d: 2-28                 [-1, 512, 4, 4]           1,024\n",
      "|    └─ReLU: 2-29                        [-1, 512, 4, 4]           --\n",
      "|    └─Conv2d: 2-30                      [-1, 512, 4, 4]           2,359,808\n",
      "|    └─BatchNorm2d: 2-31                 [-1, 512, 4, 4]           1,024\n",
      "|    └─ReLU: 2-32                        [-1, 512, 4, 4]           --\n",
      "|    └─MaxPool2d: 2-33                   [-1, 512, 2, 2]           --\n",
      "├─Sequential: 1-5                        [-1, 512, 1, 1]           --\n",
      "|    └─Conv2d: 2-34                      [-1, 512, 2, 2]           2,359,808\n",
      "|    └─BatchNorm2d: 2-35                 [-1, 512, 2, 2]           1,024\n",
      "|    └─ReLU: 2-36                        [-1, 512, 2, 2]           --\n",
      "|    └─Conv2d: 2-37                      [-1, 512, 2, 2]           2,359,808\n",
      "|    └─BatchNorm2d: 2-38                 [-1, 512, 2, 2]           1,024\n",
      "|    └─ReLU: 2-39                        [-1, 512, 2, 2]           --\n",
      "|    └─Conv2d: 2-40                      [-1, 512, 2, 2]           2,359,808\n",
      "|    └─BatchNorm2d: 2-41                 [-1, 512, 2, 2]           1,024\n",
      "|    └─ReLU: 2-42                        [-1, 512, 2, 2]           --\n",
      "|    └─MaxPool2d: 2-43                   [-1, 512, 1, 1]           --\n",
      "├─Sequential: 1-6                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-44                     [-1, 512]                 --\n",
      "|    └─Linear: 2-45                      [-1, 4096]                2,101,248\n",
      "|    └─ReLU: 2-46                        [-1, 4096]                --\n",
      "├─Sequential: 1-7                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-47                     [-1, 4096]                --\n",
      "|    └─Linear: 2-48                      [-1, 4096]                16,781,312\n",
      "|    └─ReLU: 2-49                        [-1, 4096]                --\n",
      "├─Sequential: 1-8                        [-1, 10]                  --\n",
      "|    └─Linear: 2-50                      [-1, 10]                  40,970\n",
      "==========================================================================================\n",
      "Total params: 33,646,538\n",
      "Trainable params: 33,646,538\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 365.75\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.78\n",
      "Params size (MB): 128.35\n",
      "Estimated Total Size (MB): 132.14\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 16, 16]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          1,792\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n",
       "|    └─ReLU: 2-3                         [-1, 64, 32, 32]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 64, 32, 32]          36,928\n",
       "|    └─ReLU: 2-5                         [-1, 64, 32, 32]          --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 64, 16, 16]          --\n",
       "├─Sequential: 1-2                        [-1, 128, 8, 8]           --\n",
       "|    └─Conv2d: 2-7                       [-1, 128, 16, 16]         73,856\n",
       "|    └─BatchNorm2d: 2-8                  [-1, 128, 16, 16]         256\n",
       "|    └─ReLU: 2-9                         [-1, 128, 16, 16]         --\n",
       "|    └─Conv2d: 2-10                      [-1, 128, 16, 16]         147,584\n",
       "|    └─BatchNorm2d: 2-11                 [-1, 128, 16, 16]         256\n",
       "|    └─ReLU: 2-12                        [-1, 128, 16, 16]         --\n",
       "|    └─MaxPool2d: 2-13                   [-1, 128, 8, 8]           --\n",
       "├─Sequential: 1-3                        [-1, 256, 4, 4]           --\n",
       "|    └─Conv2d: 2-14                      [-1, 256, 8, 8]           295,168\n",
       "|    └─BatchNorm2d: 2-15                 [-1, 256, 8, 8]           512\n",
       "|    └─ReLU: 2-16                        [-1, 256, 8, 8]           --\n",
       "|    └─Conv2d: 2-17                      [-1, 256, 8, 8]           590,080\n",
       "|    └─BatchNorm2d: 2-18                 [-1, 256, 8, 8]           512\n",
       "|    └─ReLU: 2-19                        [-1, 256, 8, 8]           --\n",
       "|    └─Conv2d: 2-20                      [-1, 256, 8, 8]           590,080\n",
       "|    └─BatchNorm2d: 2-21                 [-1, 256, 8, 8]           512\n",
       "|    └─ReLU: 2-22                        [-1, 256, 8, 8]           --\n",
       "|    └─MaxPool2d: 2-23                   [-1, 256, 4, 4]           --\n",
       "├─Sequential: 1-4                        [-1, 512, 2, 2]           --\n",
       "|    └─Conv2d: 2-24                      [-1, 512, 4, 4]           1,180,160\n",
       "|    └─BatchNorm2d: 2-25                 [-1, 512, 4, 4]           1,024\n",
       "|    └─ReLU: 2-26                        [-1, 512, 4, 4]           --\n",
       "|    └─Conv2d: 2-27                      [-1, 512, 4, 4]           2,359,808\n",
       "|    └─BatchNorm2d: 2-28                 [-1, 512, 4, 4]           1,024\n",
       "|    └─ReLU: 2-29                        [-1, 512, 4, 4]           --\n",
       "|    └─Conv2d: 2-30                      [-1, 512, 4, 4]           2,359,808\n",
       "|    └─BatchNorm2d: 2-31                 [-1, 512, 4, 4]           1,024\n",
       "|    └─ReLU: 2-32                        [-1, 512, 4, 4]           --\n",
       "|    └─MaxPool2d: 2-33                   [-1, 512, 2, 2]           --\n",
       "├─Sequential: 1-5                        [-1, 512, 1, 1]           --\n",
       "|    └─Conv2d: 2-34                      [-1, 512, 2, 2]           2,359,808\n",
       "|    └─BatchNorm2d: 2-35                 [-1, 512, 2, 2]           1,024\n",
       "|    └─ReLU: 2-36                        [-1, 512, 2, 2]           --\n",
       "|    └─Conv2d: 2-37                      [-1, 512, 2, 2]           2,359,808\n",
       "|    └─BatchNorm2d: 2-38                 [-1, 512, 2, 2]           1,024\n",
       "|    └─ReLU: 2-39                        [-1, 512, 2, 2]           --\n",
       "|    └─Conv2d: 2-40                      [-1, 512, 2, 2]           2,359,808\n",
       "|    └─BatchNorm2d: 2-41                 [-1, 512, 2, 2]           1,024\n",
       "|    └─ReLU: 2-42                        [-1, 512, 2, 2]           --\n",
       "|    └─MaxPool2d: 2-43                   [-1, 512, 1, 1]           --\n",
       "├─Sequential: 1-6                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-44                     [-1, 512]                 --\n",
       "|    └─Linear: 2-45                      [-1, 4096]                2,101,248\n",
       "|    └─ReLU: 2-46                        [-1, 4096]                --\n",
       "├─Sequential: 1-7                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-47                     [-1, 4096]                --\n",
       "|    └─Linear: 2-48                      [-1, 4096]                16,781,312\n",
       "|    └─ReLU: 2-49                        [-1, 4096]                --\n",
       "├─Sequential: 1-8                        [-1, 10]                  --\n",
       "|    └─Linear: 2-50                      [-1, 10]                  40,970\n",
       "==========================================================================================\n",
       "Total params: 33,646,538\n",
       "Trainable params: 33,646,538\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 365.75\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 3.78\n",
       "Params size (MB): 128.35\n",
       "Estimated Total Size (MB): 132.14\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16(input_shape=3, output_shape=len(classes)).to(device)\n",
    "summary(model, (3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nTRAINING\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"{batch_idx}: Loss: {(train_loss/(batch_idx+1)):.3f} | Acc: {(100.0*correct/total):.3f} | Correct/Total: {correct}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "def test(epoch):\n",
    "    print(\"TESTING\")\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f\"{batch_idx}: Loss: {(test_loss/(batch_idx+1)):.3f} | Acc: {(100.0*correct/total):.3f} | Correct/Total: {correct}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 0\n",
      "0: Loss: 0.295 | Acc: 91.406 | Correct/Total: 117/128\n",
      "50: Loss: 0.404 | Acc: 86.688 | Correct/Total: 5659/6528\n",
      "100: Loss: 0.401 | Acc: 86.649 | Correct/Total: 11202/12928\n",
      "150: Loss: 0.401 | Acc: 86.651 | Correct/Total: 16748/19328\n",
      "200: Loss: 0.405 | Acc: 86.447 | Correct/Total: 22241/25728\n",
      "250: Loss: 0.408 | Acc: 86.317 | Correct/Total: 27732/32128\n",
      "300: Loss: 0.411 | Acc: 86.150 | Correct/Total: 33192/38528\n",
      "350: Loss: 0.411 | Acc: 86.245 | Correct/Total: 38748/44928\n",
      "TESTING\n",
      "0: Loss: 0.449 | Acc: 85.938 | Correct/Total: 110/128\n",
      "50: Loss: 0.467 | Acc: 84.436 | Correct/Total: 5512/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:20<12:00, 80.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 1\n",
      "0: Loss: 0.278 | Acc: 91.406 | Correct/Total: 117/128\n",
      "50: Loss: 0.378 | Acc: 87.439 | Correct/Total: 5708/6528\n",
      "100: Loss: 0.383 | Acc: 87.260 | Correct/Total: 11281/12928\n",
      "150: Loss: 0.379 | Acc: 87.412 | Correct/Total: 16895/19328\n",
      "200: Loss: 0.380 | Acc: 87.426 | Correct/Total: 22493/25728\n",
      "250: Loss: 0.382 | Acc: 87.288 | Correct/Total: 28044/32128\n",
      "300: Loss: 0.382 | Acc: 87.274 | Correct/Total: 33625/38528\n",
      "350: Loss: 0.384 | Acc: 87.208 | Correct/Total: 39181/44928\n",
      "TESTING\n",
      "0: Loss: 0.362 | Acc: 89.062 | Correct/Total: 114/128\n",
      "50: Loss: 0.450 | Acc: 84.819 | Correct/Total: 5537/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:40<10:43, 80.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 2\n",
      "0: Loss: 0.312 | Acc: 86.719 | Correct/Total: 111/128\n",
      "50: Loss: 0.364 | Acc: 88.373 | Correct/Total: 5769/6528\n",
      "100: Loss: 0.369 | Acc: 88.088 | Correct/Total: 11388/12928\n",
      "150: Loss: 0.363 | Acc: 88.069 | Correct/Total: 17022/19328\n",
      "200: Loss: 0.371 | Acc: 87.640 | Correct/Total: 22548/25728\n",
      "250: Loss: 0.370 | Acc: 87.649 | Correct/Total: 28160/32128\n",
      "300: Loss: 0.372 | Acc: 87.516 | Correct/Total: 33718/38528\n",
      "350: Loss: 0.372 | Acc: 87.522 | Correct/Total: 39322/44928\n",
      "TESTING\n",
      "0: Loss: 0.370 | Acc: 91.406 | Correct/Total: 117/128\n",
      "50: Loss: 0.439 | Acc: 85.892 | Correct/Total: 5607/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [04:00<09:22, 80.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 3\n",
      "0: Loss: 0.320 | Acc: 85.938 | Correct/Total: 110/128\n",
      "50: Loss: 0.339 | Acc: 88.097 | Correct/Total: 5751/6528\n",
      "100: Loss: 0.340 | Acc: 88.188 | Correct/Total: 11401/12928\n",
      "150: Loss: 0.341 | Acc: 88.317 | Correct/Total: 17070/19328\n",
      "200: Loss: 0.342 | Acc: 88.417 | Correct/Total: 22748/25728\n",
      "250: Loss: 0.344 | Acc: 88.284 | Correct/Total: 28364/32128\n",
      "300: Loss: 0.347 | Acc: 88.222 | Correct/Total: 33990/38528\n",
      "350: Loss: 0.345 | Acc: 88.330 | Correct/Total: 39685/44928\n",
      "TESTING\n",
      "0: Loss: 0.400 | Acc: 85.938 | Correct/Total: 110/128\n",
      "50: Loss: 0.445 | Acc: 85.202 | Correct/Total: 5562/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [05:17<07:53, 79.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 4\n",
      "0: Loss: 0.238 | Acc: 91.406 | Correct/Total: 117/128\n",
      "50: Loss: 0.311 | Acc: 89.568 | Correct/Total: 5847/6528\n",
      "100: Loss: 0.310 | Acc: 89.604 | Correct/Total: 11584/12928\n",
      "150: Loss: 0.315 | Acc: 89.404 | Correct/Total: 17280/19328\n",
      "200: Loss: 0.314 | Acc: 89.401 | Correct/Total: 23001/25728\n",
      "250: Loss: 0.318 | Acc: 89.315 | Correct/Total: 28695/32128\n",
      "300: Loss: 0.319 | Acc: 89.182 | Correct/Total: 34360/38528\n",
      "350: Loss: 0.321 | Acc: 89.172 | Correct/Total: 40063/44928\n",
      "TESTING\n",
      "0: Loss: 0.416 | Acc: 85.156 | Correct/Total: 109/128\n",
      "50: Loss: 0.445 | Acc: 85.080 | Correct/Total: 5554/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [06:37<06:35, 79.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 5\n",
      "0: Loss: 0.367 | Acc: 86.719 | Correct/Total: 111/128\n",
      "50: Loss: 0.292 | Acc: 90.211 | Correct/Total: 5889/6528\n",
      "100: Loss: 0.300 | Acc: 90.006 | Correct/Total: 11636/12928\n",
      "150: Loss: 0.298 | Acc: 90.087 | Correct/Total: 17412/19328\n",
      "200: Loss: 0.299 | Acc: 89.945 | Correct/Total: 23141/25728\n",
      "250: Loss: 0.303 | Acc: 89.785 | Correct/Total: 28846/32128\n",
      "300: Loss: 0.304 | Acc: 89.719 | Correct/Total: 34567/38528\n",
      "350: Loss: 0.303 | Acc: 89.746 | Correct/Total: 40321/44928\n",
      "TESTING\n",
      "0: Loss: 0.364 | Acc: 86.719 | Correct/Total: 111/128\n",
      "50: Loss: 0.413 | Acc: 86.443 | Correct/Total: 5643/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [07:56<05:17, 79.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 6\n",
      "0: Loss: 0.292 | Acc: 90.625 | Correct/Total: 116/128\n",
      "50: Loss: 0.266 | Acc: 91.192 | Correct/Total: 5953/6528\n",
      "100: Loss: 0.281 | Acc: 90.811 | Correct/Total: 11740/12928\n",
      "150: Loss: 0.281 | Acc: 90.630 | Correct/Total: 17517/19328\n",
      "200: Loss: 0.287 | Acc: 90.407 | Correct/Total: 23260/25728\n",
      "250: Loss: 0.289 | Acc: 90.364 | Correct/Total: 29032/32128\n",
      "300: Loss: 0.288 | Acc: 90.386 | Correct/Total: 34824/38528\n",
      "350: Loss: 0.287 | Acc: 90.400 | Correct/Total: 40615/44928\n",
      "TESTING\n",
      "0: Loss: 0.392 | Acc: 89.062 | Correct/Total: 114/128\n",
      "50: Loss: 0.437 | Acc: 85.463 | Correct/Total: 5579/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [09:16<03:57, 79.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 7\n",
      "0: Loss: 0.200 | Acc: 94.531 | Correct/Total: 121/128\n",
      "50: Loss: 0.264 | Acc: 91.452 | Correct/Total: 5970/6528\n",
      "100: Loss: 0.268 | Acc: 91.174 | Correct/Total: 11787/12928\n",
      "150: Loss: 0.272 | Acc: 91.034 | Correct/Total: 17595/19328\n",
      "200: Loss: 0.272 | Acc: 90.913 | Correct/Total: 23390/25728\n",
      "250: Loss: 0.275 | Acc: 90.837 | Correct/Total: 29184/32128\n",
      "300: Loss: 0.274 | Acc: 90.872 | Correct/Total: 35011/38528\n",
      "350: Loss: 0.277 | Acc: 90.734 | Correct/Total: 40765/44928\n",
      "TESTING\n",
      "0: Loss: 0.409 | Acc: 86.719 | Correct/Total: 111/128\n",
      "50: Loss: 0.448 | Acc: 85.738 | Correct/Total: 5597/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [10:35<02:38, 79.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 8\n",
      "0: Loss: 0.202 | Acc: 93.750 | Correct/Total: 120/128\n",
      "50: Loss: 0.249 | Acc: 91.207 | Correct/Total: 5954/6528\n",
      "100: Loss: 0.248 | Acc: 91.368 | Correct/Total: 11812/12928\n",
      "150: Loss: 0.249 | Acc: 91.417 | Correct/Total: 17669/19328\n",
      "200: Loss: 0.252 | Acc: 91.433 | Correct/Total: 23524/25728\n",
      "250: Loss: 0.257 | Acc: 91.304 | Correct/Total: 29334/32128\n",
      "300: Loss: 0.258 | Acc: 91.279 | Correct/Total: 35168/38528\n",
      "350: Loss: 0.259 | Acc: 91.259 | Correct/Total: 41001/44928\n",
      "TESTING\n",
      "0: Loss: 0.330 | Acc: 91.406 | Correct/Total: 117/128\n",
      "50: Loss: 0.434 | Acc: 86.106 | Correct/Total: 5621/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [11:55<01:19, 79.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING\n",
      "Epoch: 9\n",
      "0: Loss: 0.233 | Acc: 93.750 | Correct/Total: 120/128\n",
      "50: Loss: 0.251 | Acc: 91.789 | Correct/Total: 5992/6528\n",
      "100: Loss: 0.247 | Acc: 91.677 | Correct/Total: 11852/12928\n",
      "150: Loss: 0.249 | Acc: 91.582 | Correct/Total: 17701/19328\n",
      "200: Loss: 0.250 | Acc: 91.550 | Correct/Total: 23554/25728\n",
      "250: Loss: 0.250 | Acc: 91.574 | Correct/Total: 29421/32128\n",
      "300: Loss: 0.253 | Acc: 91.487 | Correct/Total: 35248/38528\n",
      "350: Loss: 0.253 | Acc: 91.511 | Correct/Total: 41114/44928\n",
      "TESTING\n",
      "0: Loss: 0.334 | Acc: 92.188 | Correct/Total: 118/128\n",
      "50: Loss: 0.422 | Acc: 86.734 | Correct/Total: 5662/6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:15<00:00, 79.50s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCH)):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), ROOT / \"cifar-10-batches-py\" / \"models\" / \"VGG16.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module,\n",
    "                     data,\n",
    "                     device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Prepare the sample (add a batch dimension and pass to target device)\n",
    "        data = torch.unsqueeze(data, dim=0).to(device)      \n",
    "        # Forward pass (model outputs raw logits)\n",
    "        pred_logits = model(data)     \n",
    "        # Get prediction probability (logit -> prediction probability)\n",
    "        pred_prob = torch.softmax(pred_logits.squeeze(), dim=0)     \n",
    "        # Get pred_prob off the GPU for futher calculation\n",
    "        pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    # Stack the pred_probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 1800)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"/home/famousdeer/Desktop/Praca magisterska/Program/data/cifar-10-batches-py/test.jpg\")\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((32,32))\n",
    "img = transforms.ToTensor()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16(input_shape=3, output_shape=len(classes))\n",
    "model.load_state_dict(torch.load(ROOT / \"cifar-10-batches-py\" / \"models\" / \"VGG16.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = make_predictions(model=model,\n",
    "                              data=img,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes= pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.title(classes[pred_classes])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0277]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0409]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0192]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0234]],\n",
       "\n",
       "         [[0.0057]],\n",
       "\n",
       "         [[0.0189]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0249]],\n",
       "\n",
       "         [[0.0286]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0035]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0164]],\n",
       "\n",
       "         [[0.0112]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0022]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0334]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0255]],\n",
       "\n",
       "         [[0.0005]],\n",
       "\n",
       "         [[0.0180]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0243]],\n",
       "\n",
       "         [[0.0151]],\n",
       "\n",
       "         [[0.0176]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0032]],\n",
       "\n",
       "         [[0.0176]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0167]],\n",
       "\n",
       "         [[0.0186]],\n",
       "\n",
       "         [[0.0287]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0247]],\n",
       "\n",
       "         [[0.0045]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0057]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0012]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0128]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0171]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0055]],\n",
       "\n",
       "         [[0.0198]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0241]],\n",
       "\n",
       "         [[0.0162]],\n",
       "\n",
       "         [[0.0040]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0134]],\n",
       "\n",
       "         [[0.0111]],\n",
       "\n",
       "         [[0.0083]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0038]],\n",
       "\n",
       "         [[0.0270]],\n",
       "\n",
       "         [[0.0036]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0129]],\n",
       "\n",
       "         [[0.0335]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0121]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0236]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0193]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0152]],\n",
       "\n",
       "         [[0.0110]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0018]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0122]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0430]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0348]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0191]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0049]],\n",
       "\n",
       "         [[0.0049]],\n",
       "\n",
       "         [[0.0265]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0180]],\n",
       "\n",
       "         [[0.0181]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0071]],\n",
       "\n",
       "         [[0.0396]],\n",
       "\n",
       "         [[0.0071]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0223]],\n",
       "\n",
       "         [[0.0105]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0352]],\n",
       "\n",
       "         [[0.0415]],\n",
       "\n",
       "         [[0.0216]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0257]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0398]],\n",
       "\n",
       "         [[0.0316]],\n",
       "\n",
       "         [[0.0031]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0046]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0233]],\n",
       "\n",
       "         [[0.0025]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0134]],\n",
       "\n",
       "         [[0.0094]],\n",
       "\n",
       "         [[0.0057]],\n",
       "\n",
       "         [[0.0143]],\n",
       "\n",
       "         [[0.0100]],\n",
       "\n",
       "         [[0.0273]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0133]],\n",
       "\n",
       "         [[0.0514]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0151]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0193]],\n",
       "\n",
       "         [[0.0076]],\n",
       "\n",
       "         [[0.0026]],\n",
       "\n",
       "         [[0.0061]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0036]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0020]],\n",
       "\n",
       "         [[0.0087]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0154]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0282]],\n",
       "\n",
       "         [[0.0012]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0033]],\n",
       "\n",
       "         [[0.0059]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0037]],\n",
       "\n",
       "         [[0.0208]],\n",
       "\n",
       "         [[0.0070]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0130]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0107]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0088]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0138]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0056]],\n",
       "\n",
       "         [[0.0028]],\n",
       "\n",
       "         [[0.0036]],\n",
       "\n",
       "         [[0.0005]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0228]],\n",
       "\n",
       "         [[0.0176]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0138]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0028]],\n",
       "\n",
       "         [[0.0316]],\n",
       "\n",
       "         [[0.0293]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0485]],\n",
       "\n",
       "         [[0.0002]],\n",
       "\n",
       "         [[0.0089]],\n",
       "\n",
       "         [[0.0124]],\n",
       "\n",
       "         [[0.0115]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0006]],\n",
       "\n",
       "         [[0.0164]],\n",
       "\n",
       "         [[0.0126]],\n",
       "\n",
       "         [[0.0392]],\n",
       "\n",
       "         [[0.0189]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0313]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0325]],\n",
       "\n",
       "         [[0.0268]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0264]],\n",
       "\n",
       "         [[0.0208]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0041]],\n",
       "\n",
       "         [[0.0000]],\n",
       "\n",
       "         [[0.0000]]]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.randn((1,3,300,300))\n",
    "model_2 = VGGBase()\n",
    "model_3 = VGGAuxiliaryConvolutional()\n",
    "model_3(model_2(test_tensor)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
